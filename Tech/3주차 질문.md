기술
Statistics/Math : 엔트로피(Entropy)에 대해 설명해주세요. 가능하면 정보이득(Information Gain)도요.
- Entropy는 줘진 데이터 집합의 혼잡도를 의미하며, 1로 갈수록 불순하고, 0으로 갈수록 불순하지 않다는 의미입니다. 즉, 엔트로피는 0에서 1까지의 값을 갖게 되는데, 즉 엔트로피가 0일때는 같은 데이터 결과만 존재하는 것이고 엔트로피가 1일때는 전혀 분리가 안되어 있다는 것을 의미합니다.
- 정보이득이란 결정트리에서 엔트로피를 계산 후, 어떤 노드를 선택하는 것이 옳은지 따져볼 때 사용하는 기댓값입니다. 결정 트리에서 다양한 노드를 만들고 엔트로피를 구했다면 정보 이들이 가장 높은 값을 선택하고 다음 가지를 생성하게 됩니다.

- 꼬리질문 : 정보 이득 공식
  - Information Gain = (Enropy before split) - (weighted entropy after split)
  - 정보이득의 공식은 위와 같이 이전 엔트로피의 값을 현재 엔트로피 값들을 뺀 것입니다. 이전 엔트로피의 이후의 값들은 이전 엔트로피보다 더 값이 좋아야 되기 때문에 엔트로피 값이 낮을 것이며, 이 둘의 차는 높아질수록 잘 분리된 값이 됩니다.

Statistics/Math : 로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요.
- 취하는경우는 정규성을 높이고 분석시에 정확한 값을 얻기 위함입니다. 단위수가 너무 큰 값들을 바로 회귀분석 할 경우, 결과를 왜곡할 우려가 있으므로 이를 방지하기 위해 로그함수를 취해줍니다. 또한 로그함수를 취함으로써 비선형관계의 데이터를 선형으로 만들 수 있습니다.
예시) 연령 같은 경우에는 숫자의 범위가 약 0세~120세 이하지만, 재산 보유액 같은 경우에는 0원에서 몇 조까지 올라갈 수 있습니다. 이럴 경우 데이터 간 단위가 달라지면 결과값이 이상해 질 수 있기 때문에 log를 이용해 큰 수를 같은 비율의 작은 수로 바꿔줍니다.

Machine Learning : SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?
- SVM을 비선형 분류 모델로 사용하기 위해 저차원 공간의 데이터를 고차원 공간으로 매핑하여 선형 분리가 가능한 데이터로 변환하여 처리합니다.
SVM이 좋은 이유는 SVM은 데이터들을 선형 분리하며 최대 마진의 초평면을 찾는 크게 복잡하지 않은 구조이며, 커널 트릭을 이용해 차원을 늘리면서 비선형 데이터들에도 좋은 결과를 얻을 수 있습니다. 또한 이진 분류 뿐만 아니라 수치 예측에도 사용될 수 있습니다. Overfitting 경향이 낮으며 노이즈 데이터에도 크게 영향을 받지 않습니다.


Machine Learning : ROC 커브에 대해 설명해주실 수 있으신가요?
ROC 커브는 정답이 아닌 것을 정답으로 추론하는 확률을 x축으로 두고 이를 0부터 1로 키워가면서 정답을 정답으로 맞추는 확률을 y축으로 하여 나타낸 그래프를 의미합니다. 이 그래프는 y=x를 기준으로 멀리 떨어질 수록 모델의 성능이 좋다고 판단할 수 있으며, ROC 커브의 하단 영역을 AUC 값으로 하여 ROC-AUC Score로 계산하게 됩니다.
ROC 커브는 왼쪽 상단에 가까울수록 좋습니다. 즉 AUC가 클수록 좋습니다.


Deep Learning : Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?
딥러닝에서 가중치를 잘 초기화하는 것은 기울기 소실이나 local minima 등의 문제를 야기할 수 있기 때문에 중요합니다.
초기화 방법에는 Xavier Initialization과 He Initialization 등이 있습니다.

- Xavier Initialization : 들어오는 노드 수와 나가는 노드 수에 의존하고, 적절한 상수 값도 발견하여 사용하는 방법입니다. Sigmoid이나 tanh 함수와는 좋은 결과를 보여주지만 ReLU 함수와 사용할 경우 0에 수렴하는 문제가 발생합니다. 따라서 sigmoid나 tanh함수와 주로 많이 사용됩니다.
- He Initialization : ReLU와 함께 많이 사용되는 방법으로, 들어오는 노드만 고려합니다. (보충 설명 필요)

Statistics/Math : 베이즈 정리에 대해 설명해주세요.
- 베이즈 정리는 사건 𝐵가 발생함으로써 사건 𝐴의 확률이 어떻게 변화하는지를 표현한 정리입니다. 따라서 베이즈 정리는 새로운 정보가 기존의 추론에 어떻게 영향을 미치는지를 나타냅니다.
![image](https://user-images.githubusercontent.com/90206705/232432591-15e0edf3-3d56-44ba-a768-4044b2bc43c6.png)


Machine Learning : 회귀 / 분류시 알맞은 손실함수와 이에 대한 설명
- 회귀에서 사용되는 손실 함수는 대표적으로 평균 오차 계산법이 있으며, 평균 오차를 계산하는 방식에 따라 MAE, MSE, RMSE로 구분됩니다.
분류에 사용되는 손실 함수는 대표적으로 cross entropy 방식이 있습니다.

- MAE : 모든 절대오차의 평균
- MSE : 예측값과 실제값 사이의 평균을 제곱하여 평균 낸 값
- RMSE : MSE에 루트 -> 제곱된 값에 루트를 씌우기 떄문에 제곱해서 생기는 왜곡이 줄어들며, 오차를 보다 직관적으로 보여줍니다. 
- 꼬리 질문 : Cross Entropy의 종류
  - Binary cross-entropy, Categorical cross-entropy, 

Deep Learning : 알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)
- Activation Function의 종류로는 출력 값을 0과 1 사이로 변경해주는 Sigmoid 함수와 출력값을 -1과 1 사이로 압축시켜주는 tanh, 양수면 그대로, 음수면 0을 출력하는 ReLU등이 있습니다.

[꼬리질문]
- Sigmoid : 입력 값이 크거나 작을 때 기울기가 0에 가까워지는 saturation 문제가 있다. 이는 gradient vanishing 문제를 야기하므로 요즘에는 활성화 함수로서 잘 사용되지 않는다. 또한 값이 zero-centered 가 아니기 때문에 입력값의 부호에 그대로 영향을 받으므로 경사하강법 과정에서 정확한 방향으로 가지 못하고 지그재그로 움직이는 문제가 있다. 
- tanh : 입력값이 0에 가까울수록 미분이 크기 때문에 출력값이 빠르게 변하지만 Sigmoid와 마찬가지로 gradient vanishing 문제가 있습니다.
- ReLU : 양의 입력에 대해서는 saturation 문제가 발생하지 않는다. 음의 입력 값에 대해서는 어떤 업데이트도 되지 않는 Dead ReLU 문제가 발생한다.


Deep Learning : pytorch의 dataloader에서 GPU가 어떻게 사용되는가?
device = torch.device('cuda')
model.to(device)

[꼬리질문] GPU 2개 다 쓰고 싶은 방법
Pytorch의 경우 torch.nn.DataParallel을 사용하여 여러 개의 GPU를 사용할 수 있다.

torch.device를 cuda로 설정한다.
nn.DataParallel을 사용하여 모델을 감싼다.
모델을 model.to(device)를 사용하여 GPU로 보낸다.

Operating System : 캐시의 지역성에 대해 설명해주세요.
- 캐시가 효율적으로 동작하려면, 캐시에 저장할 데이터가 지역성을 가져야 한다. 지역성이란 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 말한다.

[꼬리질문 1] 지역성의 원리
[꼬리질문 2] 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성

Statistics/Math: 신뢰 구간(Confidence Interval;CI)의 정의는 무엇인가요?
- 신뢰구간은 모수가 실제로 포함될 것으로 예측되는 범위입니다. 집단 전체를 연구하는 것을 불가능하므로, 샘플링된 데이터를 기반으로 모수의 범위를 추정하기 위해 사용됩니다. 따라서, 신뢰 구간은 샘플링된 표본이 연구중인 모집단을 얼마나 잘 대표하는지 측정하는 방법입니다. 일반적으로 95% 신뢰ㅜ준이 사용됩니다.
- 꼬리질문 : 신뢰 구간 공식

Statistics/Math: 평균(mean)과 중앙값(median)중에 어떤 케이스에서 뭐를 써야할까요?
- 평균은 모든 관측값의 합을 자료의 개수로 나눈 것입니다. 평균 근처에 표본이 있다면 경향성을 파악하기 쉽지만 극단적인 값에 영향을 많이 받기에 아주 작은 값이나 큰 값에 큰 영향을 받습니다. 중앙값은 전체 관측값을 크기 순서로 배열했을 때 중앙에 위치한 값으로 가운데 위치하는 값 이외에 다른 값들의 영향을 받지 않기에 이상치에 민감하지 않습니다. 즉, 왜곡이 심한 데이터의 경우일 때 유용합니다.

Statistics/Math: 필요한 표본의 크기를 어떻게 계산합니까?
![image](https://user-images.githubusercontent.com/90206705/232524877-537946b1-2acd-4423-be72-4df05cf43c8d.png)
N = 모집단 크기 • e = 오차 한계(십진수 형식의 백분율) • z = z점수
모집단의 크기 N을 구하고, 신뢰수준 z와 오차범위 e를 얼마로 할지 선정하여 표본의 크기를 구할 수 있습니다. 이때 주의 할 점은 오차 한계를 더 작게 하려면 동일한 모집단에서 표본 크기가 더 커야 하고 더 높은 표집 신뢰 수준을 원한다면 표본 크기도 더 커져야 합니다.

Machine Learning: 최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?
- 뉴턴법은 어떤 함수의 영점을 모를 때 아무점이나 찍은 후 그 점에서의 기울기를 구해서 점점 영점에 다가가는 방법입니다. 함수가 미분 가능해야하고 미분값이 0이 지점이 없어야합니다. (초기값을 잘 주면 금방 해를 찾을 수 있지만 잘못 주면 시간이 오래 걸리거나 아예 해를 찾지 못할 수 있습니다.)
- 경사 하강법은 극소점을 찾기 위해서 기울기를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동하는 것을 반복하는 방법입니다. 뉴턴 법과 다른 점은 뉴턴법은 급진적으로 이동하는 반면 경사 하강법은 이동할 거리를 조절할 수 있는 매개변수가 있고(lr) 일반적으로 낮은 숫자로 설정하여 천처니 이동합니다.


Machine Learning: 머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?
- 머신러닝은 예측(prediction)에 집중하고 머신러닝의 측정은 예측의 퍼포먼스를 통해 하게 됩니다. 모델의 복잡성보다는 overfitting을 고려합니다. 반면 통계적 접근 방법은 모델의 복잡성보다는 단순성을 추구합니다. 또 parameter의 해석가능성과, 모델링과 샘플링의 가정에 강조합니다.

Deep Learning: 하이퍼 파라미터는 무엇인가요?
머신러닝에서 하이퍼파라미터는 최적의 훈련 모델을 구현하기 위해 개발자에 의해 수동으로 설정할 수 있습니다. 모델에 설정하는 변수로 learning rate, epoch 등을 결정할 수 있습니다. 또한 하이퍼파라미터 튜닝 기법을 적용하여 훈련 모델의 최적값들을 찾을 수 있습니다.

[꼬리질문]
파라미터와의 차이 : 파라미터는 데이터로부터 추정 또는 학습됩니다. 개발자의 의해 수동으로 설정하지 않고 임의의 조정이 불가능합니다.

Deep Learning: 미니배치를 작게 할때의 장단점은?
전체 데이터를 쪼개서 여러 번 학습하기 때문에, 전체 Training 데이터 셋을 배치로 사용것보다 계산량이 적어(즉 메모리 사용량이 적어), 학습 속도가 빠르다는 장점이 있습니다. 반면에 big batch보다 느리고 loss function의 최솟값을 찾기 위해 자주 step의 방향을 바꿔야 하므로 학습이 불안정한 단점이 있습니다.

## 인성
- 비 IT 동료와 효과적으로 의사소통하려면 어떻게 할지 말해주세요.
최대한 전문용어는 빼고 결과 중심으로 명확히 의사전달을 할 것입니다. 또한, 자료를 쓸 수 있다면 시각적 자료를 통해 결과물이나 요청사항 등으로 이해시킬 것입니다.

- 이상적인 개발 환경이란 무엇이라고 생각하시나요?
제가 생각하는 이상적인 개발 환경이란 같이 개발지식을 나눌 동료들이 있고 피드백을 해줄 시니어들이 있는 것입니다.

- 상사와 의견차가 좁혀지지 않는 갈등이 일어났을 때 어떻게 해결할 것인가?
먼저 상사의 의견에 질문을 많이 하여 의견이 타당한 이유를 찾을 것 같습니다. 무조건적인 수용보다 타당한 이유를 알고 의견을 받아들인다면 더 일의 효율이 높아지기 때문입니다. 

- 어떤 개발자가 잘하는 개발자라고 생각하는가?


- 간단한 1분 자기소개 부탁드려요
- 최근 관심있는 분야가 있으신가요?
